{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For each ticker (company), store all news into a dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Return one season's financial news dataframe\n",
    "def season_dataframe(ticker, season):\n",
    "    with open('./financial_news/'+ticker+str(season), 'r') as ticker_news:\n",
    "        content  = ticker_news.read()\n",
    "    records = json.loads(content)\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Create dataframe for each ticker, storing its news\n",
    "#ALL_TICKERS = [\"$TSLA\", \"$NVDA\", \"$INTC\", \"$PFE\", \"$SPGI\", \"$LRCX\", \"$TMUS\", \"$ADSK\", \"$VRTX\", \"$TWTR\", \"$EBAY\", \"$CARR\", \"$VRSN\", \"$GRMN\", \"$ANET\", \"$AAL\"]\n",
    "ALL_TICKERS = [\"$TSLA\", \"$NVDA\", \"$INTC\", \"$PFE\", \"$SPGI\", \"$LRCX\", \"$TMUS\", \"$ADSK\", \"$VRTX\", \"$TWTR\", \"$EBAY\", \"$CARR\", \"$GRMN\", \"$ANET\", \"$AAL\"]\n",
    "#ALL_TICKERS = [\"$TSLA\"]\n",
    "df = []\n",
    "for ticker in ALL_TICKERS:\n",
    "  # Concatenate 8 seasons into one dataframe\n",
    "  df_temp = pd.DataFrame()\n",
    "  for i in range(1, 9):\n",
    "      new_df = season_dataframe(ticker, i)\n",
    "      df_temp = pd.concat([df_temp, new_df], ignore_index=True)\n",
    "  df.append(df_temp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usage: df[0] will return $TSLA news from 2019-01-01 to 2020-12-31"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate Polarity of each news, using nltk.sentiment.vader package"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Calculate vader\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Helper function, which calculates the sentiment and returns compund score\n",
    "def cal_compound(t):\n",
    "    return vader.polarity_scores(t)[\"compound\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for each_df in df:\n",
    "  each_df['title_compound'] = each_df['title'].apply(cal_compound)\n",
    "  each_df['text_compound'] = each_df['text'].apply(cal_compound)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert publishedDate to YYYY-MM-DD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Helper function: for the date conversion\n",
    "def remove_time(publish_date):\n",
    "  return publish_date[0:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for each_df in df:\n",
    "  each_df['publishedDate'] = each_df['publishedDate'].apply(remove_time)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert weekend to next Monday"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Helper function: Convert weekend to next Monday\n",
    "def moveWeekend(publish_date):\n",
    "  d = datetime.datetime(int(publish_date[0:4]), int(publish_date[5:7]), int(publish_date[8:10]))\n",
    "  if (d.weekday() == 5):\n",
    "    return str(d+datetime.timedelta(days=2))[0:10]\n",
    "  elif (d.weekday() == 6):\n",
    "    return str(d+datetime.timedelta(days=1))[0:10]\n",
    "  else:\n",
    "    return publish_date"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for each_df in df:\n",
    "  each_df['publishedDate'] = each_df['publishedDate'].apply(moveWeekend)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate title and text's daily polarity mean respectively"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "polarity = []\n",
    "# Calcuate mean on daily basis\n",
    "for each_df in df:\n",
    "  each_title_mean = each_df.groupby('publishedDate', as_index=False)['title_compound'].mean()\n",
    "  each_text_mean = each_df.groupby('publishedDate', as_index=False)['text_compound'].mean()\n",
    "  each_polarity = pd.merge(each_title_mean, each_text_mean, on='publishedDate')\n",
    "  each_polarity['symbol'] = each_df['symbol']\n",
    "  polarity.append(each_polarity)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge everyday's closing price with polarity dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Helper function: Fetch closing price by a specific date and ticker name\n",
    "def fetchClosingPrice(time, ticker):\n",
    "  data = pd.read_csv(\"./stock_price/compare_previous_day/\"+ticker+\".csv\")\n",
    "  data = data[data.Date.isin([time])]\n",
    "  data = data['Close']\n",
    "  #return data.iloc[0].item()\n",
    "  return 0 if len(data.index) == 0 else data.iloc[0].item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for each_polarity in polarity:\n",
    "  each_polarity['close_price'] = each_polarity['publishedDate'].apply(fetchClosingPrice, args=(each_polarity.symbol.iloc[0],))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge everyday's indicator with polarity dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def fetchIndicator(time, ticker):\n",
    "  data = pd.read_csv(\"./stock_price/compare_previous_day/\"+ticker+\".csv\")\n",
    "  data = data[data.Date.isin([time])]\n",
    "  data = data['indicator']\n",
    "  #return data.iloc[0].item()\n",
    "  return 0 if len(data.index) == 0 else data.iloc[0].item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "for each_polarity in polarity:\n",
    "  each_polarity['indicator'] = each_polarity['publishedDate'].apply(fetchIndicator, args=(each_polarity.symbol.iloc[0],))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "polarity[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    publishedDate  title_compound  text_compound symbol  close_price  \\\n",
       "0      2019-01-01       -0.226300      -0.296000   TSLA     0.000000   \n",
       "1      2019-01-03       -0.526700      -0.128000   TSLA    60.071999   \n",
       "2      2019-01-07        0.000000       0.000000   TSLA    66.991997   \n",
       "3      2019-01-17       -0.273200       0.025800   TSLA    69.461998   \n",
       "4      2019-01-18       -0.340000      -0.440400   TSLA    60.452000   \n",
       "..            ...             ...            ...    ...          ...   \n",
       "429    2020-12-25        0.148000       0.509500   TSLA     0.000000   \n",
       "430    2020-12-28        0.081800       0.378638   TSLA   663.690002   \n",
       "431    2020-12-29        0.209004       0.202939   TSLA   665.989990   \n",
       "432    2020-12-30        0.209600       0.323291   TSLA   694.780029   \n",
       "433    2020-12-31        0.191190       0.302485   TSLA   705.669983   \n",
       "\n",
       "     indicator  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          0.0  \n",
       "..         ...  \n",
       "429        0.0  \n",
       "430        1.0  \n",
       "431        1.0  \n",
       "432        1.0  \n",
       "433        1.0  \n",
       "\n",
       "[434 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>title_compound</th>\n",
       "      <th>text_compound</th>\n",
       "      <th>symbol</th>\n",
       "      <th>close_price</th>\n",
       "      <th>indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>-0.226300</td>\n",
       "      <td>-0.296000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>-0.526700</td>\n",
       "      <td>-0.128000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>60.071999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>66.991997</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>69.461998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>-0.440400</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>60.452000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.378638</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>663.690002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>0.209004</td>\n",
       "      <td>0.202939</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>665.989990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.323291</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>694.780029</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.191190</td>\n",
       "      <td>0.302485</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>705.669983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add S&P 500 Adj Close into dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "sp_df = pd.read_csv(\"./stock_price/original/S&P500.csv\")\n",
    "sp_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Date      Open      High       Low    Close\n",
       "0    12-31-2020  3,733.27  3,760.20  3,726.88  3756.07\n",
       "1    12-30-2020  3,736.19  3,744.63  3,730.21  3732.04\n",
       "2    12-29-2020  3,750.01  3,756.12  3,723.31  3727.04\n",
       "3    12-28-2020  3,723.03  3,740.51  3,723.03  3735.36\n",
       "4    12-24-2020  3,694.03  3,703.82  3,689.32  3703.06\n",
       "..          ...       ...       ...       ...      ...\n",
       "500  01-08-2019  2,568.11  2,579.82  2,547.56  2574.41\n",
       "501  01-07-2019  2,535.61  2,566.16  2,524.56  2549.69\n",
       "502  01-04-2019  2,474.33  2,538.07  2,474.33  2531.94\n",
       "503  01-03-2019  2,491.92  2,493.14  2,443.96  2447.89\n",
       "504  01-02-2019  2,476.96  2,519.49  2,467.47  2510.03\n",
       "\n",
       "[505 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-31-2020</td>\n",
       "      <td>3,733.27</td>\n",
       "      <td>3,760.20</td>\n",
       "      <td>3,726.88</td>\n",
       "      <td>3756.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-30-2020</td>\n",
       "      <td>3,736.19</td>\n",
       "      <td>3,744.63</td>\n",
       "      <td>3,730.21</td>\n",
       "      <td>3732.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-29-2020</td>\n",
       "      <td>3,750.01</td>\n",
       "      <td>3,756.12</td>\n",
       "      <td>3,723.31</td>\n",
       "      <td>3727.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-28-2020</td>\n",
       "      <td>3,723.03</td>\n",
       "      <td>3,740.51</td>\n",
       "      <td>3,723.03</td>\n",
       "      <td>3735.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-24-2020</td>\n",
       "      <td>3,694.03</td>\n",
       "      <td>3,703.82</td>\n",
       "      <td>3,689.32</td>\n",
       "      <td>3703.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>01-08-2019</td>\n",
       "      <td>2,568.11</td>\n",
       "      <td>2,579.82</td>\n",
       "      <td>2,547.56</td>\n",
       "      <td>2574.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>01-07-2019</td>\n",
       "      <td>2,535.61</td>\n",
       "      <td>2,566.16</td>\n",
       "      <td>2,524.56</td>\n",
       "      <td>2549.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>01-04-2019</td>\n",
       "      <td>2,474.33</td>\n",
       "      <td>2,538.07</td>\n",
       "      <td>2,474.33</td>\n",
       "      <td>2531.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>01-03-2019</td>\n",
       "      <td>2,491.92</td>\n",
       "      <td>2,493.14</td>\n",
       "      <td>2,443.96</td>\n",
       "      <td>2447.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>01-02-2019</td>\n",
       "      <td>2,476.96</td>\n",
       "      <td>2,519.49</td>\n",
       "      <td>2,467.47</td>\n",
       "      <td>2510.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def reorder_date(date):\n",
    "  return date[6:10]+'-'+date[0:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "sp_df['publishedDate'] = sp_df['Date'].apply(reorder_date)\n",
    "sp_df = sp_df[['publishedDate', 'Close']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "sp_df = sp_df.iloc[::-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "sp_df = sp_df.rename(columns= {'Close': \"s&p500_close_price\"}, inplace=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Convert str to float\n",
    "sp_df['s&p500_close_price'] = pd.to_numeric(sp_df['s&p500_close_price'], downcast=\"float\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "for i in range(len(polarity)):\n",
    "  polarity[i] = pd.merge(polarity[i], sp_df, on=\"publishedDate\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training and Testing Step"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for each_polarity in polarity:\n",
    "  y = each_polarity['indicator']\n",
    "  X = each_polarity.drop(columns=['indicator','publishedDate','symbol'])\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = scaler.transform(X_train)\n",
    "  X_test = scaler.transform(X_test)\n",
    "  \n",
    "  # apply RandomForestRegressor\n",
    "  out_date = each_polarity.publishedDate.values\n",
    "  rf = RandomForestRegressor(n_estimators=150)\n",
    "  rf.fit(X_train, y_train)\n",
    "  y_pred = rf.predict(X_test)\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  corr = np.corrcoef(X_train, y_train, rowvar=False)[-1, :-1]\n",
    "  corr = corr.max()\n",
    "  f = open(each_polarity.symbol.iloc[0]+\".summary.csv\", \"w\")\n",
    "  f.write(\"MSE,correlation\\n\")\n",
    "  f.write(\"{},{:.2f}\\n\".format(mse, corr))\n",
    "  f.close()\n",
    "\n",
    "  f = open(each_polarity.symbol.iloc[0]+\".output.csv\", \"w\")\n",
    "  f.write(\"date,predicted_indicator\\n\")\n",
    "  for i in range(y_pred.shape[0]):\n",
    "      f.write(\"{},{}\\n\".format(out_date[i], y_pred[i]))\n",
    "  f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "avg_accuracy = 0\n",
    "for each_polarity in polarity:\n",
    "  y = each_polarity['indicator']\n",
    "  X = each_polarity.drop(columns=['indicator','publishedDate','symbol'])\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = scaler.transform(X_train)\n",
    "  X_test = scaler.transform(X_test)\n",
    "  \n",
    "  # apply MLPClassifier\n",
    "  out_date = each_polarity.publishedDate.values\n",
    "  #rf = RandomForestRegressor(n_estimators=150)\n",
    "  nn = MLPClassifier(\n",
    "    hidden_layer_sizes=(90,10),\n",
    "    random_state=0,\n",
    "    max_iter=60,\n",
    "  )\n",
    "  nn.fit(X_train, y_train)\n",
    "  #rf.fit(X_train, y_train)\n",
    "  y_pred = nn.predict(X_test)\n",
    "  #print(accuracy_score(y_test, y_pred))\n",
    "  avg_accuracy+=accuracy_score(y_test, y_pred)\n",
    "  #mse = mean_squared_error(y_test, y_pred)\n",
    "  #corr = np.corrcoef(X_train, y_train, rowvar=False)[-1, :-1]\n",
    "  #corr = corr.max()\n",
    "  \"\"\" accuracy = accuracy_score(y_test, y_pred)\n",
    "  f = open(each_polarity.symbol.iloc[0]+\".summary.csv\", \"w\")\n",
    "  f.write(\"accuracy\\n\")\n",
    "  f.write(\"{:.2f}\\n\".format(accuracy))\n",
    "  f.close()\n",
    "\n",
    "  f = open(each_polarity.symbol.iloc[0]+\".output.csv\", \"w\")\n",
    "  f.write(\"date,predicted_indicator\\n\")\n",
    "  for i in range(y_pred.shape[0]):\n",
    "      f.write(\"{},{}\\n\".format(out_date[i], y_pred[i]))\n",
    "  f.close() \"\"\"\n",
    "print(avg_accuracy/15)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5529588853897907\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/vincent/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (60) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}