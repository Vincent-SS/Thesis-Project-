{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each ticker (company), store all news into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return one season's financial news dataframe\n",
    "def season_dataframe(ticker, season):\n",
    "    with open('./financial_news/'+ticker+str(season), 'r') as ticker_news:\n",
    "        content  = ticker_news.read()\n",
    "    records = json.loads(content)\n",
    "    df = pd.DataFrame(records)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for each ticker, storing its news\n",
    "#ALL_TICKERS = [\"$TSLA\", \"$NVDA\", \"$INTC\", \"$PFE\", \"$SPGI\", \"$LRCX\", \"$TMUS\", \"$ADSK\", \"$VRTX\", \"$TWTR\", \"$EBAY\", \"$CARR\", \"$VRSN\", \"$GRMN\", \"$ANET\", \"$AAL\"]\n",
    "ALL_TICKERS = [\"$TSLA\", \"$NVDA\", \"$INTC\", \"$PFE\", \"$SPGI\", \"$LRCX\", \"$TMUS\", \"$ADSK\", \"$VRTX\", \"$TWTR\", \"$EBAY\", \"$CARR\", \"$GRMN\", \"$ANET\", \"$AAL\"]\n",
    "#ALL_TICKERS = [\"$TSLA\"]\n",
    "df = []\n",
    "for ticker in ALL_TICKERS:\n",
    "  # Concatenate 8 seasons into one dataframe\n",
    "  df_temp = pd.DataFrame()\n",
    "  for i in range(1, 9):\n",
    "      new_df = season_dataframe(ticker, i)\n",
    "      df_temp = pd.concat([df_temp, new_df], ignore_index=True)\n",
    "  df.append(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: df[0] will return $TSLA news from 2019-01-01 to 2020-12-31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Polarity of each news, using nltk.sentiment.vader package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate vader\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Helper function, which calculates the sentiment and returns compund score\n",
    "def cal_compound(t):\n",
    "    return vader.polarity_scores(t)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_df in df:\n",
    "  each_df['title_compound'] = each_df['title'].apply(cal_compound)\n",
    "  each_df['text_compound'] = each_df['text'].apply(cal_compound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert publishedDate to YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: for the date conversion\n",
    "def remove_time(publish_date):\n",
    "  return publish_date[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_df in df:\n",
    "  each_df['publishedDate'] = each_df['publishedDate'].apply(remove_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weekend to next Monday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Convert weekend to next Monday\n",
    "def moveWeekend(publish_date):\n",
    "  d = datetime.datetime(int(publish_date[0:4]), int(publish_date[5:7]), int(publish_date[8:10]))\n",
    "  if (d.weekday() == 5):\n",
    "    return str(d+datetime.timedelta(days=2))[0:10]\n",
    "  elif (d.weekday() == 6):\n",
    "    return str(d+datetime.timedelta(days=1))[0:10]\n",
    "  else:\n",
    "    return publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_df in df:\n",
    "  each_df['publishedDate'] = each_df['publishedDate'].apply(moveWeekend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate title and text's daily polarity mean respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = []\n",
    "# Calcuate mean on daily basis\n",
    "for each_df in df:\n",
    "  each_title_mean = each_df.groupby('publishedDate', as_index=False)['title_compound'].mean()\n",
    "  each_text_mean = each_df.groupby('publishedDate', as_index=False)['text_compound'].mean()\n",
    "  each_polarity = pd.merge(each_title_mean, each_text_mean, on='publishedDate')\n",
    "  each_polarity['symbol'] = each_df['symbol']\n",
    "  polarity.append(each_polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge everyday's closing price with polarity dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Fetch closing price by a specific date and ticker name\n",
    "def fetchClosingPrice(time, ticker):\n",
    "  data = pd.read_csv(\"./stock_price/\"+ticker+\".csv\")\n",
    "  data = data[data.Date.isin([time])]\n",
    "  data = data['Close']\n",
    "  #return data.iloc[0].item()\n",
    "  return 0 if len(data.index) == 0 else data.iloc[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_polarity in polarity:\n",
    "  each_polarity['close_price'] = each_polarity['publishedDate'].apply(fetchClosingPrice, args=(each_polarity.symbol.iloc[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add S&P 500 Adj Close into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12-31-2020</td>\n",
       "      <td>3,733.27</td>\n",
       "      <td>3,760.20</td>\n",
       "      <td>3,726.88</td>\n",
       "      <td>3756.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-30-2020</td>\n",
       "      <td>3,736.19</td>\n",
       "      <td>3,744.63</td>\n",
       "      <td>3,730.21</td>\n",
       "      <td>3732.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12-29-2020</td>\n",
       "      <td>3,750.01</td>\n",
       "      <td>3,756.12</td>\n",
       "      <td>3,723.31</td>\n",
       "      <td>3727.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12-28-2020</td>\n",
       "      <td>3,723.03</td>\n",
       "      <td>3,740.51</td>\n",
       "      <td>3,723.03</td>\n",
       "      <td>3735.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12-24-2020</td>\n",
       "      <td>3,694.03</td>\n",
       "      <td>3,703.82</td>\n",
       "      <td>3,689.32</td>\n",
       "      <td>3703.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>01-08-2019</td>\n",
       "      <td>2,568.11</td>\n",
       "      <td>2,579.82</td>\n",
       "      <td>2,547.56</td>\n",
       "      <td>2574.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>01-07-2019</td>\n",
       "      <td>2,535.61</td>\n",
       "      <td>2,566.16</td>\n",
       "      <td>2,524.56</td>\n",
       "      <td>2549.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>01-04-2019</td>\n",
       "      <td>2,474.33</td>\n",
       "      <td>2,538.07</td>\n",
       "      <td>2,474.33</td>\n",
       "      <td>2531.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>01-03-2019</td>\n",
       "      <td>2,491.92</td>\n",
       "      <td>2,493.14</td>\n",
       "      <td>2,443.96</td>\n",
       "      <td>2447.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>01-02-2019</td>\n",
       "      <td>2,476.96</td>\n",
       "      <td>2,519.49</td>\n",
       "      <td>2,467.47</td>\n",
       "      <td>2510.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Open      High       Low    Close\n",
       "0    12-31-2020  3,733.27  3,760.20  3,726.88  3756.07\n",
       "1    12-30-2020  3,736.19  3,744.63  3,730.21  3732.04\n",
       "2    12-29-2020  3,750.01  3,756.12  3,723.31  3727.04\n",
       "3    12-28-2020  3,723.03  3,740.51  3,723.03  3735.36\n",
       "4    12-24-2020  3,694.03  3,703.82  3,689.32  3703.06\n",
       "..          ...       ...       ...       ...      ...\n",
       "500  01-08-2019  2,568.11  2,579.82  2,547.56  2574.41\n",
       "501  01-07-2019  2,535.61  2,566.16  2,524.56  2549.69\n",
       "502  01-04-2019  2,474.33  2,538.07  2,474.33  2531.94\n",
       "503  01-03-2019  2,491.92  2,493.14  2,443.96  2447.89\n",
       "504  01-02-2019  2,476.96  2,519.49  2,467.47  2510.03\n",
       "\n",
       "[505 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df = pd.read_csv(\"./stock_price/S&P500.csv\")\n",
    "sp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_date(date):\n",
    "  return date[6:10]+'-'+date[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df['publishedDate'] = sp_df['Date'].apply(reorder_date)\n",
    "sp_df = sp_df[['publishedDate', 'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = sp_df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = sp_df.rename(columns= {'Close': \"s&p500_close_price\"}, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert str to float\n",
    "sp_df['s&p500_close_price'] = pd.to_numeric(sp_df['s&p500_close_price'], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(polarity)):\n",
    "  polarity[i] = pd.merge(polarity[i], sp_df, on=\"publishedDate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_polarity in polarity:\n",
    "  y = each_polarity['close_price']\n",
    "  X = each_polarity.drop(columns=['close_price','publishedDate','symbol'])\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train = scaler.transform(X_train)\n",
    "  X_test = scaler.transform(X_test)\n",
    "  \n",
    "  # apply RandomForestRegressor\n",
    "  out_date = each_polarity.publishedDate.values\n",
    "  rf = RandomForestRegressor(n_estimators=150)\n",
    "  rf.fit(X_train, y_train)\n",
    "  y_pred = rf.predict(X_test)\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  corr = np.corrcoef(X_train, y_train, rowvar=False)[-1, :-1]\n",
    "  corr = corr.max()\n",
    "  f = open(each_polarity.symbol.iloc[0]+\".summary.csv\", \"w\")\n",
    "  f.write(\"MSE,correlation\\n\")\n",
    "  f.write(\"{},{:.2f}\\n\".format(mse, corr))\n",
    "  f.close()\n",
    "\n",
    "  f = open(each_polarity.symbol.iloc[0]+\".output.csv\", \"w\")\n",
    "  f.write(\"date,predicted_closing_price\\n\")\n",
    "  for i in range(y_pred.shape[0]):\n",
    "      f.write(\"{},{}\\n\".format(out_date[i], y_pred[i]))\n",
    "  f.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}